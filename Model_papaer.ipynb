{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import more_itertools as mit\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import History, EarlyStopping\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHANNEL = \"D-12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Channel:\n",
    "    def __init__(self, chan_id):\n",
    "        self.id = chan_id\n",
    "        self.train = None\n",
    "        self.test = None\n",
    "        self.l_s = 250\n",
    "        self.n_predictions = 10\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.X_test = None\n",
    "        self.y_test = None\n",
    "        self.y_hat = None\n",
    "\n",
    "    def shape_data(self, arr, training=True):\n",
    "        data = []\n",
    "        for i in range(len(arr) - self.l_s - self.n_predictions):\n",
    "            data.append(arr[i: i + self.l_s + self.n_predictions])\n",
    "            \n",
    "        data = np.array(data)\n",
    "\n",
    "        if training:\n",
    "            np.random.shuffle(data)\n",
    "            self.X_train = data[:, :-self.n_predictions, :]\n",
    "            self.y_train = data[:, -self.n_predictions:, 0]\n",
    "        else:\n",
    "            self.X_test = data[:, :-self.n_predictions, :]\n",
    "            self.y_test = data[:, -self.n_predictions:, 0]\n",
    "\n",
    "    def load_data(self):\n",
    "        try:\n",
    "            self.train = np.load(os.path.join(\"data\", \"train\", \"{}.npy\".format(self.id)))\n",
    "            self.test = np.load(os.path.join(\"data\", \"test\", \"{}.npy\".format(self.id)))\n",
    "        except FileNotFoundError as e:\n",
    "            print(e)\n",
    "\n",
    "        self.shape_data(self.train)\n",
    "        self.shape_data(self.test, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_channel = Channel(CHANNEL)\n",
    "new_channel.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, channel):\n",
    "        self.chan_id = channel.id\n",
    "        self.y_hat = np.array([])\n",
    "        self.model = None\n",
    "        self.train_new(channel)\n",
    "        \n",
    "\n",
    "    def train_new(self, channel):\n",
    "        cbs = [History(), EarlyStopping(monitor='val_loss',\n",
    "                                        patience=10,\n",
    "                                        min_delta=0.0003,\n",
    "                                        verbose=0)]\n",
    "\n",
    "        self.model = Sequential()\n",
    "\n",
    "        self.model.add(LSTM(\n",
    "            80,\n",
    "            input_shape=(None, channel.X_train.shape[2]),\n",
    "            return_sequences=True))\n",
    "        self.model.add(Dropout(0.3))\n",
    "\n",
    "        self.model.add(LSTM(\n",
    "            80,\n",
    "            return_sequences=False))\n",
    "        self.model.add(Dropout(0.3))\n",
    "\n",
    "        self.model.add(Dense(\n",
    "            channel.n_predictions))\n",
    "        self.model.add(Activation('linear'))\n",
    "\n",
    "        self.model.compile(loss='mse',\n",
    "                           optimizer='adam')\n",
    "\n",
    "        self.model.fit(channel.X_train,\n",
    "                       channel.y_train,\n",
    "                       batch_size=64,\n",
    "                       epochs=35,\n",
    "                       validation_split=0.2,\n",
    "                       callbacks=cbs,\n",
    "                       verbose=True)\n",
    "        \n",
    "    def aggregate_predictions(self, y_hat_batch, method='first'):\n",
    "        agg_y_hat_batch = np.array([])\n",
    "\n",
    "        for t in range(len(y_hat_batch)):\n",
    "\n",
    "            start_idx = t - 10\n",
    "            start_idx = start_idx if start_idx >= 0 else 0\n",
    "\n",
    "            # predictions pertaining to a specific timestep lie along diagonal\n",
    "            y_hat_t = np.flipud(y_hat_batch[start_idx:t+1]).diagonal()\n",
    "\n",
    "            if method == 'first':\n",
    "                agg_y_hat_batch = np.append(agg_y_hat_batch, [y_hat_t[0]])\n",
    "            elif method == 'mean':\n",
    "                agg_y_hat_batch = np.append(agg_y_hat_batch, np.mean(y_hat_t))\n",
    "\n",
    "        agg_y_hat_batch = agg_y_hat_batch.reshape(len(agg_y_hat_batch), 1)\n",
    "        self.y_hat = np.append(self.y_hat, agg_y_hat_batch)\n",
    "              \n",
    "    def batch_predict(self, channel):\n",
    "        num_batches = int((channel.y_test.shape[0] - 250)\n",
    "                          / 70)\n",
    "\n",
    "        for i in range(0, num_batches + 1):\n",
    "            prior_idx = i * 70\n",
    "            idx = (i + 1) * 70\n",
    "\n",
    "            if i + 1 == num_batches + 1:\n",
    "                idx = channel.y_test.shape[0]\n",
    "\n",
    "            X_test_batch = channel.X_test[prior_idx:idx]\n",
    "            y_hat_batch = self.model.predict(X_test_batch)\n",
    "            self.aggregate_predictions(y_hat_batch)\n",
    "\n",
    "        self.y_hat = np.reshape(self.y_hat, (self.y_hat.size,))\n",
    "\n",
    "        channel.y_hat = self.y_hat\n",
    "\n",
    "        return channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 13:30:28.174687: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-03-25 13:30:28.174851: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 13:30:29.208790: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-03-25 13:30:31.452786: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-25 13:30:32.142573: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-25 13:30:38.471166: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-25 13:30:44.715969: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-25 13:31:26.054907: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 1.0057"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 13:32:05.300130: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-25 13:32:05.465792: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-25 13:32:09.277141: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 103s 103s/step - loss: 1.0057 - val_loss: 0.9129\n",
      "Epoch 2/35\n",
      "1/1 [==============================] - 0s 416ms/step - loss: 0.9201 - val_loss: 0.8237\n",
      "Epoch 3/35\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.8340 - val_loss: 0.7263\n",
      "Epoch 4/35\n",
      "1/1 [==============================] - 0s 392ms/step - loss: 0.7409 - val_loss: 0.6144\n",
      "Epoch 5/35\n",
      "1/1 [==============================] - 0s 345ms/step - loss: 0.6348 - val_loss: 0.4831\n",
      "Epoch 6/35\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.5121 - val_loss: 0.3366\n",
      "Epoch 7/35\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.3778 - val_loss: 0.2008\n",
      "Epoch 8/35\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.2577 - val_loss: 0.1154\n",
      "Epoch 9/35\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.1882 - val_loss: 0.0835\n",
      "Epoch 10/35\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.1694 - val_loss: 0.0707\n",
      "Epoch 11/35\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.1658 - val_loss: 0.0553\n",
      "Epoch 12/35\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.1562 - val_loss: 0.0365\n",
      "Epoch 13/35\n",
      "1/1 [==============================] - 0s 316ms/step - loss: 0.1404 - val_loss: 0.0204\n",
      "Epoch 14/35\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.1249 - val_loss: 0.0119\n",
      "Epoch 15/35\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.1149 - val_loss: 0.0117\n",
      "Epoch 16/35\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.1113 - val_loss: 0.0166\n",
      "Epoch 17/35\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.1114 - val_loss: 0.0222\n",
      "Epoch 18/35\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.1117 - val_loss: 0.0257\n",
      "Epoch 19/35\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.1101 - val_loss: 0.0264\n",
      "Epoch 20/35\n",
      "1/1 [==============================] - 0s 324ms/step - loss: 0.1060 - val_loss: 0.0245\n",
      "Epoch 21/35\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.0999 - val_loss: 0.0209\n",
      "Epoch 22/35\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.0927 - val_loss: 0.0167\n",
      "Epoch 23/35\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0856 - val_loss: 0.0128\n",
      "Epoch 24/35\n",
      "1/1 [==============================] - 0s 322ms/step - loss: 0.0790 - val_loss: 0.0095\n",
      "Epoch 25/35\n",
      "1/1 [==============================] - 0s 318ms/step - loss: 0.0737 - val_loss: 0.0073\n",
      "Epoch 26/35\n",
      "1/1 [==============================] - 0s 321ms/step - loss: 0.0696 - val_loss: 0.0061\n",
      "Epoch 27/35\n",
      "1/1 [==============================] - 0s 320ms/step - loss: 0.0668 - val_loss: 0.0057\n",
      "Epoch 28/35\n",
      "1/1 [==============================] - 0s 319ms/step - loss: 0.0649 - val_loss: 0.0057\n",
      "Epoch 29/35\n",
      "1/1 [==============================] - 0s 334ms/step - loss: 0.0635 - val_loss: 0.0058\n",
      "Epoch 30/35\n",
      "1/1 [==============================] - 0s 332ms/step - loss: 0.0623 - val_loss: 0.0059\n",
      "Epoch 31/35\n",
      "1/1 [==============================] - 0s 330ms/step - loss: 0.0611 - val_loss: 0.0058\n",
      "Epoch 32/35\n",
      "1/1 [==============================] - 0s 327ms/step - loss: 0.0597 - val_loss: 0.0055\n",
      "Epoch 33/35\n",
      "1/1 [==============================] - 0s 328ms/step - loss: 0.0581 - val_loss: 0.0052\n",
      "Epoch 34/35\n",
      "1/1 [==============================] - 0s 344ms/step - loss: 0.0565 - val_loss: 0.0048\n",
      "Epoch 35/35\n",
      "1/1 [==============================] - 0s 331ms/step - loss: 0.0549 - val_loss: 0.0046\n"
     ]
    }
   ],
   "source": [
    "model = Model(new_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 13:32:24.011699: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-25 13:32:24.155671: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-03-25 13:32:27.301110: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.Channel at 0x1062e3ca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.batch_predict(new_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plotter:\n",
    "    def __init__(self, channel):\n",
    "        self.channel = channel\n",
    "\n",
    "    def plot_predictions(self, plot_real_data=True):\n",
    "        if plot_real_data:\n",
    "            plt.plot(self.channel.y_test[:, 0])\n",
    "        else:\n",
    "            plt.plot(self.channel.y_hat)\n",
    "\n",
    "        anomalies = pd.read_csv(\"data/labeled_anomalies.csv\")\n",
    "        anomalies = anomalies[anomalies[\"chan_id\"] == self.channel.id]\n",
    "        anomalies_plot = anomalies['anomaly_sequences']\n",
    "        anomalies_plot = eval(anomalies_plot.iloc[0])\n",
    "\n",
    "        for rect in anomalies_plot:\n",
    "            plt.axvspan(rect[0], rect[1], alpha=0.3, color='red')\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def plot_custom_range_predictions(self, start, end, plot_real_data=True):\n",
    "        if plot_real_data:\n",
    "            plt.plot([i for i in range(start, end)], self.channel.y_test[:, 0][start:end])\n",
    "        else:\n",
    "             plt.plot([i for i in range(start, end)], self.channel.y_hat[start:end])\n",
    "\n",
    "        anomalies = pd.read_csv(\"data/labeled_anomalies.csv\")\n",
    "        anomalies = anomalies[anomalies[\"chan_id\"] == self.channel.id]\n",
    "        anomalies_plot = anomalies['anomaly_sequences']\n",
    "        anomalies_plot = eval(anomalies_plot.iloc[0])\n",
    "\n",
    "        for rect in anomalies_plot:\n",
    "            if max(rect[0], start) <  min(rect[1], end):\n",
    "                plt.axvspan(max(rect[0], start), min(rect[1], end), alpha=0.3, color='red')\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_threshold(self, error, threshold):\n",
    "        plt.figure(figsize=(20,10))\n",
    "        plt.plot(error)\n",
    "        plt.plot([threshold for i in range(len(error))])\n",
    "\n",
    "        anomalies = pd.read_csv(\"data/labeled_anomalies.csv\")\n",
    "        anomalies = anomalies[anomalies[\"chan_id\"] == self.channel.id]\n",
    "        anomalies_plot = anomalies['anomaly_sequences']\n",
    "        anomalies_plot = eval(anomalies_plot.iloc[0])\n",
    "\n",
    "        for rect in anomalies_plot:\n",
    "            plt.axvspan(rect[0], rect[1], alpha=0.3, color='red')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_detected_anomalies(self, d_anomalies, plot_real_data=True):\n",
    "        if plot_real_data:\n",
    "            plt.plot(self.channel.y_test[:, 0])\n",
    "        else:\n",
    "            plt.plot(self.channel.y_hat)\n",
    "\n",
    "        for rect in d_anomalies:\n",
    "            plt.axvspan(rect[0], rect[1], alpha=0.3, color='red')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original error model but without shit data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Errors_a:\n",
    "    def __init__(self, channel):\n",
    "        self.window_size = 30\n",
    "        self.batch_size = 70\n",
    "        self.smoothing_perc = 0.05\n",
    "        self.l_s = 250\n",
    "\n",
    "        self.epsilons = []\n",
    "\n",
    "        self.window_size = self.window_size\n",
    "        self.n_windows = int((channel.y_test.shape[0] -\n",
    "                              (self.batch_size * self.window_size))\n",
    "                             / self.batch_size)\n",
    "        self.i_anom = np.array([])\n",
    "        self.E_seq = []\n",
    "        self.anom_scores = []\n",
    "\n",
    "        self.e = [abs(y_h-y_t[0]) for y_h, y_t in\n",
    "                  zip(channel.y_hat, channel.y_test)]\n",
    "\n",
    "        smoothing_window = int(self.batch_size * self.window_size\n",
    "                               * self.smoothing_perc)\n",
    "\n",
    "        self.e_s = pd.DataFrame(self.e).ewm(span=smoothing_window)\\\n",
    "            .mean().values.flatten()\n",
    "\n",
    "        self.normalized = np.mean(self.e / np.ptp(channel.y_test))\n",
    "\n",
    "    def process_batches(self, channel):\n",
    "\n",
    "        for i in range(0, self.n_windows+1):\n",
    "            prior_idx = i * self.batch_size\n",
    "            idx = (self.window_size * self.batch_size) \\\n",
    "                  + (i * self.batch_size)\n",
    "\n",
    "\n",
    "            window = ErrorWindow_a(channel, prior_idx, idx, self, i)\n",
    "\n",
    "            self.epsilons.append(window.find_epsilon())\n",
    "\n",
    "            window.compare_to_epsilon(self)\n",
    "\n",
    "            if len(window.i_anom) == 0 and len(window.i_anom_inv) == 0:\n",
    "                continue\n",
    "\n",
    "            # window.prune_anoms()\n",
    "            # window.prune_anoms(inverse=True)\n",
    "\n",
    "            if len(window.i_anom) == 0 and len(window.i_anom_inv) == 0:\n",
    "                continue\n",
    "\n",
    "            window.i_anom = np.sort(np.unique(\n",
    "                np.append(window.i_anom, window.i_anom_inv))).astype('int')\n",
    "            window.score_anomalies(prior_idx)\n",
    "\n",
    "            self.i_anom = np.append(self.i_anom, window.i_anom + prior_idx)\n",
    "            self.anom_scores = self.anom_scores + window.anom_scores\n",
    "\n",
    "        if len(self.i_anom) > 0:\n",
    "            groups = [list(group) for group in\n",
    "                      mit.consecutive_groups(self.i_anom)]\n",
    "            self.E_seq = [(int(g[0]), int(g[-1])) for g in groups\n",
    "                          if not g[0] == g[-1]]\n",
    "\n",
    "            self.E_seq = [(e_seq[0] + self.l_s,\n",
    "                           e_seq[1] + self.l_s) for e_seq in self.E_seq]\n",
    "\n",
    "\n",
    "class ErrorWindow_a:\n",
    "    def __init__(self, channel, start_idx, end_idx, errors, window_num):\n",
    "\n",
    "        self.i_anom = np.array([])\n",
    "        self.E_seq = np.array([])\n",
    "        self.non_anom_max = -1000000\n",
    "        self.i_anom_inv = np.array([])\n",
    "        self.E_seq_inv = np.array([])\n",
    "        self.non_anom_max_inv = -1000000\n",
    "\n",
    "        self.anom_scores = []\n",
    "\n",
    "        self.window_num = window_num\n",
    "\n",
    "        self.sd_lim = 12.0\n",
    "        self.error_buffer = 100\n",
    "        self.batch_size = 70\n",
    "        self.p = 0.13\n",
    "        self.sd_threshold = self.sd_lim\n",
    "        self.sd_threshold_inv = self.sd_lim\n",
    "\n",
    "        self.e_s = errors.e_s[start_idx:end_idx]\n",
    "\n",
    "        self.mean_e_s = np.mean(self.e_s)\n",
    "        self.sd_e_s = np.std(self.e_s)\n",
    "        self.e_s_inv = np.array([self.mean_e_s + (self.mean_e_s - e)\n",
    "                                 for e in self.e_s])\n",
    "\n",
    "        self.epsilon = self.mean_e_s + self.sd_lim * self.sd_e_s\n",
    "        self.epsilon_inv = self.mean_e_s + self.sd_lim * self.sd_e_s\n",
    "\n",
    "        self.y_test = channel.y_test[start_idx:end_idx]\n",
    "        self.sd_values = np.std(self.y_test)\n",
    "\n",
    "        self.perc_high, self.perc_low = np.percentile(self.y_test, [95, 5])\n",
    "        self.inter_range = self.perc_high - self.perc_low\n",
    "\n",
    "        # ignore initial error values until enough history for processing\n",
    "        self.l_s = 250\n",
    "        self.num_to_ignore = self.l_s * 2\n",
    "\n",
    "    def find_epsilon(self, inverse=False):\n",
    "        e_s = self.e_s\n",
    "\n",
    "        max_score = -10000000\n",
    "\n",
    "        for z in np.arange(2, 10, 0.5):\n",
    "            epsilon = self.mean_e_s + (self.sd_e_s * z)\n",
    "\n",
    "            pruned_e_s = e_s[e_s < epsilon]\n",
    "\n",
    "            i_anom = np.argwhere(e_s >= epsilon).reshape(-1,)\n",
    "\n",
    "            if len(i_anom) > 0:\n",
    "                # group anomalous indices into continuous sequences\n",
    "                groups = [list(group) for group\n",
    "                          in mit.consecutive_groups(i_anom)]\n",
    "                E_seq = [(g[0], g[-1]) for g in groups if not g[0] == g[-1]]\n",
    "\n",
    "                mean_perc_decrease = (self.mean_e_s - np.mean(pruned_e_s)) \\\n",
    "                                     / self.mean_e_s\n",
    "                sd_perc_decrease = (self.sd_e_s - np.std(pruned_e_s)) \\\n",
    "                                   / self.sd_e_s\n",
    "                score = (mean_perc_decrease + sd_perc_decrease) \\\n",
    "                        / (len(E_seq) ** 2 + len(i_anom))\n",
    "\n",
    "                # sanity checks / guardrails\n",
    "                if score >= max_score:\n",
    "                    max_score = score\n",
    "                    self.sd_threshold = z\n",
    "                    self.epsilon = self.mean_e_s + z * self.sd_e_s\n",
    "                    print(self.epsilon, len(E_seq), len(i_anom), mean_perc_decrease, sd_perc_decrease, score)\n",
    "\n",
    "        return self.epsilon\n",
    "\n",
    "    def compare_to_epsilon(self, errors_all, inverse=False):\n",
    "        e_s = self.e_s if not inverse else self.e_s_inv\n",
    "        epsilon = self.epsilon if not inverse else self.epsilon_inv\n",
    "\n",
    "        # Check: scale of errors compared to values too small?\n",
    "        if not (self.sd_e_s > (.05 * self.sd_values) or max(self.e_s)\n",
    "                > (.05 * self.inter_range)) or not max(self.e_s) > 0.05:\n",
    "            return\n",
    "\n",
    "        i_anom = np.argwhere((e_s >= epsilon) &\n",
    "                             (e_s > 0.05 * self.inter_range)).reshape(-1,)\n",
    "\n",
    "        if len(i_anom) == 0:\n",
    "            return\n",
    "        buffer = np.arange(1, self.error_buffer+1)\n",
    "        i_anom = np.sort(np.concatenate((i_anom,\n",
    "                                         np.array([i + buffer for i in i_anom])\n",
    "                                         .flatten(),\n",
    "                                         np.array([i - buffer for i in i_anom])\n",
    "                                         .flatten())))\n",
    "        i_anom = i_anom[(i_anom < len(e_s)) & (i_anom >= 0)]\n",
    "\n",
    "        # if it is first window, ignore initial errors (need some history)\n",
    "        if self.window_num == 0:\n",
    "            i_anom = i_anom[i_anom >= self.num_to_ignore]\n",
    "        else:\n",
    "            i_anom = i_anom[i_anom >= len(e_s) - self.batch_size]\n",
    "\n",
    "        i_anom = np.sort(np.unique(i_anom))\n",
    "\n",
    "        batch_position = self.window_num * self.batch_size\n",
    "        window_indices = np.arange(0, len(e_s)) + batch_position\n",
    "        adj_i_anom = i_anom + batch_position\n",
    "        window_indices = np.setdiff1d(window_indices,\n",
    "                                      np.append(errors_all.i_anom, adj_i_anom))\n",
    "        candidate_indices = np.unique(window_indices - batch_position)\n",
    "        non_anom_max = np.max(np.take(e_s, candidate_indices))\n",
    "\n",
    "        groups = [list(group) for group in mit.consecutive_groups(i_anom)]\n",
    "        E_seq = [(g[0], g[-1]) for g in groups if not g[0] == g[-1]]\n",
    "\n",
    "        if inverse:\n",
    "            self.i_anom_inv = i_anom\n",
    "            self.E_seq_inv = E_seq\n",
    "            self.non_anom_max_inv = non_anom_max\n",
    "        else:\n",
    "            self.i_anom = i_anom\n",
    "            self.E_seq = E_seq\n",
    "            self.non_anom_max = non_anom_max\n",
    "\n",
    "    # def prune_anoms(self, inverse=False):\n",
    "    #     E_seq = self.E_seq if not inverse else self.E_seq_inv\n",
    "    #     e_s = self.e_s if not inverse else self.e_s_inv\n",
    "    #     non_anom_max = self.non_anom_max if not inverse \\\n",
    "    #         else self.non_anom_max_inv\n",
    "\n",
    "    #     if len(E_seq) == 0:\n",
    "    #         return\n",
    "\n",
    "    #     E_seq_max = np.array([max(e_s[e[0]:e[1]+1]) for e in E_seq])\n",
    "    #     E_seq_max_sorted = np.sort(E_seq_max)[::-1]\n",
    "    #     E_seq_max_sorted = np.append(E_seq_max_sorted, [non_anom_max])\n",
    "\n",
    "    #     i_to_remove = np.array([])\n",
    "    #     for i in range(0, len(E_seq_max_sorted)-1):\n",
    "    #         if (E_seq_max_sorted[i] - E_seq_max_sorted[i+1]) \\\n",
    "    #                 / E_seq_max_sorted[i] < self.p:\n",
    "    #             i_to_remove = np.append(i_to_remove, np.argwhere(\n",
    "    #                 E_seq_max == E_seq_max_sorted[i]))\n",
    "    #         else:\n",
    "    #             i_to_remove = np.array([])\n",
    "    #     i_to_remove[::-1].sort()\n",
    "\n",
    "    #     if len(i_to_remove) > 0:\n",
    "    #         E_seq = np.delete(E_seq, i_to_remove, axis=0)\n",
    "\n",
    "    #     if len(E_seq) == 0 and inverse:\n",
    "    #         self.i_anom_inv = np.array([])\n",
    "    #         return\n",
    "    #     elif len(E_seq) == 0 and not inverse:\n",
    "    #         self.i_anom = np.array([])\n",
    "    #         return\n",
    "\n",
    "    #     indices_to_keep = np.concatenate([range(e_seq[0], e_seq[-1]+1)\n",
    "    #                                       for e_seq in E_seq])\n",
    "\n",
    "    #     if not inverse:\n",
    "    #         mask = np.isin(self.i_anom, indices_to_keep)\n",
    "    #         self.i_anom = self.i_anom[mask]\n",
    "    #     else:\n",
    "    #         mask_inv = np.isin(self.i_anom_inv, indices_to_keep)\n",
    "    #         self.i_anom_inv = self.i_anom_inv[mask_inv]\n",
    "\n",
    "    def score_anomalies(self, prior_idx):\n",
    "        groups = [list(group) for group in mit.consecutive_groups(self.i_anom)]\n",
    "\n",
    "        for e_seq in groups:\n",
    "\n",
    "            score_dict = {\n",
    "                \"start_idx\": e_seq[0] + prior_idx,\n",
    "                \"end_idx\": e_seq[-1] + prior_idx,\n",
    "                \"score\": 0\n",
    "            }\n",
    "\n",
    "            score = max([abs(self.e_s[i] - self.epsilon)\n",
    "                         / (self.mean_e_s + self.sd_e_s) for i in\n",
    "                         range(e_seq[0], e_seq[-1] + 1)])\n",
    "            inv_score = max([abs(self.e_s_inv[i] - self.epsilon_inv)\n",
    "                             / (self.mean_e_s + self.sd_e_s) for i in\n",
    "                             range(e_seq[0], e_seq[-1] + 1)])\n",
    "\n",
    "            score_dict['score'] = max([score, inv_score])\n",
    "            self.anom_scores.append(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = Errors_a(new_channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01318812 0.01304503 0.01290931 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01772101 0.0175016  0.01709443 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01582012 0.01572193 0.01562584 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01672712 0.01687253 0.01698672 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01292397 0.01288679 0.01285032 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01147781 0.01146808 0.01145853 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.0110983  0.01109573 0.01109322 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01099843 0.01099775 0.01099709 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01097212 0.01097194 0.01097177 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096519 0.01096514 0.0109651  ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096336 0.01096335 0.01096334 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096288 0.01096288 0.01096287 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096275 0.01096275 0.01096275 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096272 0.01096272 0.01096272 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096271 0.01096271 0.01096271]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.01096627 0.01096641 0.01096655]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.11214255 0.11324978 0.11433626]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.15538146 0.15567349 0.15596   ]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.16678225 0.16685924 0.16693479]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.16978753 0.16980782 0.16982774]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.17057965 0.170585   0.17059025]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.17078841 0.17078982 0.1707912 ]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.17084336 0.17084373 0.1708441 ]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.1755745  0.18013022 0.18449297]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.26549212 0.26590805 0.26631611]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.28172309 0.28183269 0.28194023]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.2860009  0.28602979 0.28605813]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.28712838 0.28713599 0.28714346]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.28742554 0.28742755 0.28742952]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.37686399 0.37779332 0.37841188]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.29518565 0.29427849 0.29338731]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.25922619 0.25898136 0.25874115]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.24967002 0.24960531 0.24954181]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.24713908 0.24712197 0.24710518]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.24647122 0.24646671 0.24646228]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.24629515 0.24629396 0.24629279]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.24624876 0.24624844 0.24624814]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.21733008 0.21582604 0.21434597]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.15684985 0.15643654 0.15603102]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.14071547 0.1406065  0.14049958]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.13646236 0.13643363 0.13640545]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.13534373 0.13533614 0.13532869]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.1350446  0.13504257 0.13504059]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.13496549 0.13496495 0.13496443]\n",
      "[0.01096271 0.01096271 0.01096271 ... 0.2407747  0.24094427 0.24111068]\n",
      "[0.01096668 0.01096681 0.01096694 ... 0.24740551 0.24745031 0.24749427]\n",
      "[0.11540236 0.11644858 0.11747513 ... 0.24915428 0.24916609 0.24917767]\n",
      "[0.15624111 0.15651692 0.15678753 ... 0.24961849 0.24962174 0.24962493]\n",
      "[0.16700891 0.16708164 0.16715299 ... 0.24974363 0.24974447 0.2497453 ]\n",
      "[0.16984728 0.16986644 0.16988525 ... 0.24977728 0.24977761 0.24977793]\n",
      "[0.17059539 0.17060045 0.1706054  ... 0.24978838 0.24978845 0.24978852]\n",
      "[0.17079255 0.17079388 0.17079519 ... 0.24979118 0.2497912  0.24979122]\n"
     ]
    }
   ],
   "source": [
    "error.process_batches(new_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original error model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.018786268049486646,\n",
       " 0.015561637238074619,\n",
       " 0.01365377267731654,\n",
       " 0.012721209459892574,\n",
       " 0.011442940409924456,\n",
       " 0.011088974435834904,\n",
       " 0.010995957724711456,\n",
       " 0.01097147412557053,\n",
       " 0.010965022954666198,\n",
       " 0.010963322635557741,\n",
       " 0.010962874580306887,\n",
       " 0.010962756933574128,\n",
       " 0.010962730438894687,\n",
       " 0.01096272216593066,\n",
       " 0.010962757017175386,\n",
       " 0.010962756976671262,\n",
       " 0.010962757002901162,\n",
       " 0.010962757012370608,\n",
       " 0.010962757015043916,\n",
       " 0.010962757015760875,\n",
       " 0.010962757015950713,\n",
       " 0.010962757016000812,\n",
       " 0.01096275701601402,\n",
       " 0.010962757016017502,\n",
       " 0.01096275701601842,\n",
       " 0.010962757016018664,\n",
       " 0.010962757016018726,\n",
       " 0.010962757016018744,\n",
       " 0.010962757016018749,\n",
       " 0.010962757016018749,\n",
       " 0.010962757016018749,\n",
       " 0.010962757016018749,\n",
       " 0.010962757016018749,\n",
       " 0.010962757016018749,\n",
       " 0.010962757016018749,\n",
       " 0.010962757016018749,\n",
       " 0.010962757016018749,\n",
       " 0.010962757016018749,\n",
       " 0.010962757016018749,\n",
       " 0.010962757016018749,\n",
       " 0.010962757016018749,\n",
       " 0.010962757016018749,\n",
       " 0.010962757016018749,\n",
       " 0.010963212168430131,\n",
       " 0.033896431902574575,\n",
       " 0.06746094958822983,\n",
       " 0.09465552260501876,\n",
       " 0.11683224988301573,\n",
       " 0.13555452365718518,\n",
       " 0.15181684277800894,\n",
       " 0.16621997156703133,\n",
       " 0.17920228147639108,\n",
       " 0.20344209419337445,\n",
       " 0.23098143842431096,\n",
       " 0.2564741696616013,\n",
       " 0.27930749936780735,\n",
       " 1.3361538472375485,\n",
       " 0.3209447444800252,\n",
       " 0.34469272856213107,\n",
       " 0.3570251563595641,\n",
       " 0.36594930529861847,\n",
       " 0.37327719577593976,\n",
       " 1.5484871737112833,\n",
       " 1.5394271482387267,\n",
       " 1.5236353449911648,\n",
       " 1.5040239791371854,\n",
       " 1.4626045640151113,\n",
       " 1.416387511092271,\n",
       " 1.3666314670578046,\n",
       " 0.3753124213383431,\n",
       " 0.3688218962138464,\n",
       " 0.3612376730934817,\n",
       " 0.35360712878241407,\n",
       " 0.34408463342368906,\n",
       " 0.33727363690061735,\n",
       " 0.3378574109386906,\n",
       " 0.3391509038463814,\n",
       " 0.3403627656963595,\n",
       " 0.34135569703403223,\n",
       " 0.342086946561281]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Errors_b:\n",
    "    def __init__(self, channel):\n",
    "        self.window_size = 30\n",
    "        self.batch_size = 70\n",
    "        self.smoothing_perc = 0.05\n",
    "        self.l_s = 250\n",
    "\n",
    "        self.window_size = self.window_size\n",
    "        self.n_windows = int((channel.y_test.shape[0] -\n",
    "                              (self.batch_size * self.window_size))\n",
    "                             / self.batch_size)\n",
    "        self.i_anom = np.array([])\n",
    "        self.E_seq = []\n",
    "        self.anom_scores = []\n",
    "\n",
    "        # raw prediction error\n",
    "        self.e = [abs(y_h-y_t[0]) for y_h, y_t in\n",
    "                  zip(channel.y_hat, channel.y_test)]\n",
    "\n",
    "        smoothing_window = int(self.batch_size * self.window_size\n",
    "                               * self.smoothing_perc)\n",
    "        if not len(channel.y_hat) == len(channel.y_test):\n",
    "            raise ValueError('len(y_hat) != len(y_test): {}, {}'\n",
    "                             .format(len(channel.y_hat), len(channel.y_test)))\n",
    "\n",
    "        # smoothed prediction error\n",
    "        self.e_s = pd.DataFrame(self.e).ewm(span=smoothing_window)\\\n",
    "            .mean().values.flatten()\n",
    "\n",
    "        # for values at beginning < sequence length, just use avg\n",
    "        if not channel.id == 'C-2':  # anomaly occurs early in window\n",
    "            self.e_s[:self.l_s] = \\\n",
    "                [np.mean(self.e_s[:self.l_s * 2])] * self.l_s\n",
    "\n",
    "\n",
    "        self.normalized = np.mean(self.e / np.ptp(channel.y_test))\n",
    "\n",
    "    def adjust_window_size(self, channel):\n",
    "\n",
    "        while self.n_windows < 0:\n",
    "            self.window_size -= 1\n",
    "            self.n_windows = int((channel.y_test.shape[0]\n",
    "                                 - (self.batch_size * self.window_size))\n",
    "                                 / self.batch_size)\n",
    "            if self.window_size == 1 and self.n_windows < 0:\n",
    "                raise ValueError('Batch_size ({}) larger than y_test (len={}). '\n",
    "                                 'Adjust in config.yaml.'\n",
    "                                 .format(self.batch_size,\n",
    "                                         channel.y_test.shape[0]))\n",
    "\n",
    "    def merge_scores(self):\n",
    "        merged_scores = []\n",
    "        score_end_indices = []\n",
    "\n",
    "        for i, score in enumerate(self.anom_scores):\n",
    "            if score['start_idx']-1 not in score_end_indices:\n",
    "                merged_scores.append(score['score'])\n",
    "                score_end_indices.append(score['end_idx'])\n",
    "\n",
    "    def process_batches(self, channel):\n",
    "        self.adjust_window_size(channel)\n",
    "\n",
    "        for i in range(0, self.n_windows+1):\n",
    "            prior_idx = i * self.batch_size\n",
    "            idx = (self.window_size * self.batch_size) \\\n",
    "                  + (i * self.batch_size)\n",
    "            if i == self.n_windows:\n",
    "                idx = channel.y_test.shape[0]\n",
    "\n",
    "            window = ErrorWindow_a(channel, prior_idx, idx, self, i)\n",
    "\n",
    "            window.find_epsilon()\n",
    "            window.find_epsilon(inverse=True)\n",
    "\n",
    "            window.compare_to_epsilon(self)\n",
    "            window.compare_to_epsilon(self, inverse=True)\n",
    "\n",
    "            if len(window.i_anom) == 0 and len(window.i_anom_inv) == 0:\n",
    "                continue\n",
    "\n",
    "            # window.prune_anoms()\n",
    "            # window.prune_anoms(inverse=True)\n",
    "\n",
    "            if len(window.i_anom) == 0 and len(window.i_anom_inv) == 0:\n",
    "                continue\n",
    "\n",
    "            window.i_anom = np.sort(np.unique(\n",
    "                np.append(window.i_anom, window.i_anom_inv))).astype('int')\n",
    "            window.score_anomalies(prior_idx)\n",
    "\n",
    "            # update indices to reflect true indices in full set of values\n",
    "            self.i_anom = np.append(self.i_anom, window.i_anom + prior_idx)\n",
    "            self.anom_scores = self.anom_scores + window.anom_scores\n",
    "\n",
    "        if len(self.i_anom) > 0:\n",
    "            # group anomalous indices into continuous sequences\n",
    "            groups = [list(group) for group in\n",
    "                      mit.consecutive_groups(self.i_anom)]\n",
    "            self.E_seq = [(int(g[0]), int(g[-1])) for g in groups\n",
    "                          if not g[0] == g[-1]]\n",
    "\n",
    "            # additional shift is applied to indices so that they represent the\n",
    "            # position in the original data array, obtained from the .npy files,\n",
    "            # and not the position on y_test (See PR #27).\n",
    "            self.E_seq = [(e_seq[0] + self.l_s,\n",
    "                           e_seq[1] + self.l_s) for e_seq in self.E_seq]\n",
    "\n",
    "            self.merge_scores()\n",
    "\n",
    "\n",
    "class ErrorWindow_b:\n",
    "    def __init__(self, channel, start_idx, end_idx, errors, window_num):\n",
    "\n",
    "        self.i_anom = np.array([])\n",
    "        self.E_seq = np.array([])\n",
    "        self.non_anom_max = -1000000\n",
    "        self.i_anom_inv = np.array([])\n",
    "        self.E_seq_inv = np.array([])\n",
    "        self.non_anom_max_inv = -1000000\n",
    "\n",
    "        self.anom_scores = []\n",
    "\n",
    "        self.window_num = window_num\n",
    "\n",
    "        self.sd_lim = 12.0\n",
    "        self.error_buffer = 100\n",
    "        self.batch_size = 70\n",
    "        self.p = 0.13\n",
    "        self.sd_threshold = self.sd_lim\n",
    "        self.sd_threshold_inv = self.sd_lim\n",
    "\n",
    "        self.e_s = errors.e_s[start_idx:end_idx]\n",
    "\n",
    "        self.mean_e_s = np.mean(self.e_s)\n",
    "        self.sd_e_s = np.std(self.e_s)\n",
    "        self.e_s_inv = np.array([self.mean_e_s + (self.mean_e_s - e)\n",
    "                                 for e in self.e_s])\n",
    "\n",
    "        self.epsilon = self.mean_e_s + self.sd_lim * self.sd_e_s\n",
    "        self.epsilon_inv = self.mean_e_s + self.sd_lim * self.sd_e_s\n",
    "\n",
    "        self.y_test = channel.y_test[start_idx:end_idx]\n",
    "        self.sd_values = np.std(self.y_test)\n",
    "\n",
    "        self.perc_high, self.perc_low = np.percentile(self.y_test, [95, 5])\n",
    "        self.inter_range = self.perc_high - self.perc_low\n",
    "\n",
    "        # ignore initial error values until enough history for processing\n",
    "        self.l_s = 250\n",
    "        self.num_to_ignore = self.l_s * 2\n",
    "        # if y_test is small, ignore fewer\n",
    "        if len(channel.y_test) < 2500:\n",
    "            self.num_to_ignore = self.l_s\n",
    "        if len(channel.y_test) < 1800:\n",
    "            self.num_to_ignore = 0\n",
    "\n",
    "    def find_epsilon(self, inverse=False):\n",
    "        e_s = self.e_s if not inverse else self.e_s_inv\n",
    "\n",
    "        max_score = -10000000\n",
    "\n",
    "        for z in np.arange(2.5, self.sd_lim, 0.5):\n",
    "            epsilon = self.mean_e_s + (self.sd_e_s * z)\n",
    "\n",
    "            pruned_e_s = e_s[e_s < epsilon]\n",
    "\n",
    "            i_anom = np.argwhere(e_s >= epsilon).reshape(-1,)\n",
    "            buffer = np.arange(1, self.error_buffer)\n",
    "            i_anom = np.sort(np.concatenate((i_anom,\n",
    "                                            np.array([i+buffer for i in i_anom])\n",
    "                                             .flatten(),\n",
    "                                            np.array([i-buffer for i in i_anom])\n",
    "                                             .flatten())))\n",
    "            i_anom = i_anom[(i_anom < len(e_s)) & (i_anom >= 0)]\n",
    "            i_anom = np.sort(np.unique(i_anom))\n",
    "\n",
    "            if len(i_anom) > 0:\n",
    "                # group anomalous indices into continuous sequences\n",
    "                groups = [list(group) for group\n",
    "                          in mit.consecutive_groups(i_anom)]\n",
    "                E_seq = [(g[0], g[-1]) for g in groups if not g[0] == g[-1]]\n",
    "\n",
    "                mean_perc_decrease = (self.mean_e_s - np.mean(pruned_e_s)) \\\n",
    "                                     / self.mean_e_s\n",
    "                sd_perc_decrease = (self.sd_e_s - np.std(pruned_e_s)) \\\n",
    "                                   / self.sd_e_s\n",
    "                score = (mean_perc_decrease + sd_perc_decrease) \\\n",
    "                        / (len(E_seq) ** 2 + len(i_anom))\n",
    "\n",
    "                # sanity checks / guardrails\n",
    "                if score >= max_score and len(E_seq) <= 5 and \\\n",
    "                        len(i_anom) < (len(e_s) * 0.5):\n",
    "                    max_score = score\n",
    "                    if not inverse:\n",
    "                        self.sd_threshold = z\n",
    "                        self.epsilon = self.mean_e_s + z * self.sd_e_s\n",
    "                    else:\n",
    "                        self.sd_threshold_inv = z\n",
    "                        self.epsilon_inv = self.mean_e_s + z * self.sd_e_s\n",
    "\n",
    "    def compare_to_epsilon(self, errors_all, inverse=False):\n",
    "        e_s = self.e_s if not inverse else self.e_s_inv\n",
    "        epsilon = self.epsilon if not inverse else self.epsilon_inv\n",
    "\n",
    "        # Check: scale of errors compared to values too small?\n",
    "        if not (self.sd_e_s > (.05 * self.sd_values) or max(self.e_s)\n",
    "                > (.05 * self.inter_range)) or not max(self.e_s) > 0.05:\n",
    "            return\n",
    "\n",
    "        i_anom = np.argwhere((e_s >= epsilon) &\n",
    "                             (e_s > 0.05 * self.inter_range)).reshape(-1,)\n",
    "\n",
    "        if len(i_anom) == 0:\n",
    "            return\n",
    "        buffer = np.arange(1, self.error_buffer+1)\n",
    "        i_anom = np.sort(np.concatenate((i_anom,\n",
    "                                         np.array([i + buffer for i in i_anom])\n",
    "                                         .flatten(),\n",
    "                                         np.array([i - buffer for i in i_anom])\n",
    "                                         .flatten())))\n",
    "        i_anom = i_anom[(i_anom < len(e_s)) & (i_anom >= 0)]\n",
    "\n",
    "        # if it is first window, ignore initial errors (need some history)\n",
    "        if self.window_num == 0:\n",
    "            i_anom = i_anom[i_anom >= self.num_to_ignore]\n",
    "        else:\n",
    "            i_anom = i_anom[i_anom >= len(e_s) - self.batch_size]\n",
    "\n",
    "        i_anom = np.sort(np.unique(i_anom))\n",
    "\n",
    "        # capture max of non-anomalous values below the threshold\n",
    "        # (used in filtering process)\n",
    "        batch_position = self.window_num * self.batch_size\n",
    "        window_indices = np.arange(0, len(e_s)) + batch_position\n",
    "        adj_i_anom = i_anom + batch_position\n",
    "        window_indices = np.setdiff1d(window_indices,\n",
    "                                      np.append(errors_all.i_anom, adj_i_anom))\n",
    "        candidate_indices = np.unique(window_indices - batch_position)\n",
    "        non_anom_max = np.max(np.take(e_s, candidate_indices))\n",
    "\n",
    "        # group anomalous indices into continuous sequences\n",
    "        groups = [list(group) for group in mit.consecutive_groups(i_anom)]\n",
    "        E_seq = [(g[0], g[-1]) for g in groups if not g[0] == g[-1]]\n",
    "\n",
    "        if inverse:\n",
    "            self.i_anom_inv = i_anom\n",
    "            self.E_seq_inv = E_seq\n",
    "            self.non_anom_max_inv = non_anom_max\n",
    "        else:\n",
    "            self.i_anom = i_anom\n",
    "            self.E_seq = E_seq\n",
    "            self.non_anom_max = non_anom_max\n",
    "\n",
    "    def prune_anoms(self, inverse=False):\n",
    "        E_seq = self.E_seq if not inverse else self.E_seq_inv\n",
    "        e_s = self.e_s if not inverse else self.e_s_inv\n",
    "        non_anom_max = self.non_anom_max if not inverse \\\n",
    "            else self.non_anom_max_inv\n",
    "\n",
    "        if len(E_seq) == 0:\n",
    "            return\n",
    "\n",
    "        E_seq_max = np.array([max(e_s[e[0]:e[1]+1]) for e in E_seq])\n",
    "        E_seq_max_sorted = np.sort(E_seq_max)[::-1]\n",
    "        E_seq_max_sorted = np.append(E_seq_max_sorted, [non_anom_max])\n",
    "\n",
    "        i_to_remove = np.array([])\n",
    "        for i in range(0, len(E_seq_max_sorted)-1):\n",
    "            if (E_seq_max_sorted[i] - E_seq_max_sorted[i+1]) \\\n",
    "                    / E_seq_max_sorted[i] < self.p:\n",
    "                i_to_remove = np.append(i_to_remove, np.argwhere(\n",
    "                    E_seq_max == E_seq_max_sorted[i]))\n",
    "            else:\n",
    "                i_to_remove = np.array([])\n",
    "        i_to_remove[::-1].sort()\n",
    "\n",
    "        if len(i_to_remove) > 0:\n",
    "            E_seq = np.delete(E_seq, i_to_remove, axis=0)\n",
    "\n",
    "        if len(E_seq) == 0 and inverse:\n",
    "            self.i_anom_inv = np.array([])\n",
    "            return\n",
    "        elif len(E_seq) == 0 and not inverse:\n",
    "            self.i_anom = np.array([])\n",
    "            return\n",
    "\n",
    "        indices_to_keep = np.concatenate([range(e_seq[0], e_seq[-1]+1)\n",
    "                                          for e_seq in E_seq])\n",
    "\n",
    "        if not inverse:\n",
    "            mask = np.isin(self.i_anom, indices_to_keep)\n",
    "            self.i_anom = self.i_anom[mask]\n",
    "        else:\n",
    "            mask_inv = np.isin(self.i_anom_inv, indices_to_keep)\n",
    "            self.i_anom_inv = self.i_anom_inv[mask_inv]\n",
    "\n",
    "    def score_anomalies(self, prior_idx):\n",
    "        groups = [list(group) for group in mit.consecutive_groups(self.i_anom)]\n",
    "\n",
    "        for e_seq in groups:\n",
    "\n",
    "            score_dict = {\n",
    "                \"start_idx\": e_seq[0] + prior_idx,\n",
    "                \"end_idx\": e_seq[-1] + prior_idx,\n",
    "                \"score\": 0\n",
    "            }\n",
    "\n",
    "            score = max([abs(self.e_s[i] - self.epsilon)\n",
    "                         / (self.mean_e_s + self.sd_e_s) for i in\n",
    "                         range(e_seq[0], e_seq[-1] + 1)])\n",
    "            inv_score = max([abs(self.e_s_inv[i] - self.epsilon_inv)\n",
    "                             / (self.mean_e_s + self.sd_e_s) for i in\n",
    "                             range(e_seq[0], e_seq[-1] + 1)])\n",
    "\n",
    "            # the max score indicates whether anomaly was from regular\n",
    "            # or inverted errors\n",
    "            score_dict['score'] = max([score, inv_score])\n",
    "            self.anom_scores.append(score_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5360, 5709), (5920, 6059), (6270, 6339)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error.E_seq"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
